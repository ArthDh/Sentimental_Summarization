{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "from utils.file_utils import *\n",
    "from datasets import list_datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from IPython import get_ipython\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from Sai_Test.MergeModel import *\n",
    "from Sai_Test.ClassifierModel import *\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "get_ipython().run_line_magic('autoreload', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argmax.py\t\t\t     MergeModel_20_MSE_eqcost.pt\r\n",
      "BART_classifier_final_MSE_eqcost.pt  MergeModel_20_MSE.pt\r\n",
      "BART_classifier_final_MSE.pt\t     MergeModel_30_MSE_eqcost.pt\r\n",
      "BART_training.ipynb\t\t     MergeModel_30_MSE.pt\r\n",
      "Classification_XLNet.ipynb\t     MergeModel_40_MSE_eqcost.pt\r\n",
      "classifier_final.pt\t\t     MergeModel_40_MSE.pt\r\n",
      "ClassifierModel_o.py\t\t     MergeModel_49_MSE_eqcost.pt\r\n",
      "classifier_model.pt\t\t     MergeModel_49_MSE.pt\r\n",
      "ClassifierModel.py\t\t     MergeModel_Final.ipynb\r\n",
      "classifier.pt\t\t\t     MergeModel_Train.ipynb\r\n",
      "dataset\t\t\t\t     MergeModel_Train_MSE.ipynb\r\n",
      "differentiable_embedding.py\t     MergeModel_Train_MSE_new.ipynb\r\n",
      "Embedding_differentiable.ipynb\t     models\r\n",
      "experiment\t\t\t     __pycache__\r\n",
      "gumbel_softmax.py\t\t     README.md\r\n",
      "in_domain_dev.tsv\t\t     Sai_Test\r\n",
      "in_domain_train.tsv\t\t     Sentiment_Classifier.ipynb\r\n",
      "kl_div.py\t\t\t     softargmax.py\r\n",
      "LSTM_Tests.ipynb\t\t     Untitled.ipynb\r\n",
      "MergeModel_10_MSE_eqcost.pt\t     utils\r\n",
      "MergeModel_10_MSE.pt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_model = ClassifierModel(vocab_size, 64, 2, 2, 512)\n",
    "summary_model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_model = MergeModel(summary_model, sent_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_model.load_state_dict(torch.load('BART_classifier_final_MSE_eqcost.pt'))\n",
    "merge_model = merge_model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/tmp/xdg-cache/huggingface/datasets/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = dataset['train']['text']\n",
    "train_labels = torch.tensor(dataset['train']['label'])\n",
    "val_batch = dataset['test']['text']\n",
    "val_labels = torch.tensor(dataset['test']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 150\n",
    "input_encoding = tokenizer(train_batch, return_tensors='pt', padding=True, truncation = True, max_length=seq_length)\n",
    "val_encoding = tokenizer(val_batch, return_tensors='pt', padding=True, truncation = True, max_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input_encoding['input_ids']\n",
    "input_mask = input_encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = val_encoding['input_ids']\n",
    "val_mask = val_encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 11,490\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6158</th>\n",
       "      <td>A woman who already has four children is set t...</td>\n",
       "      <td>Nadine Crooks, 33, has four children aged 18 y...</td>\n",
       "      <td>7b1bd79278c2ced9eb271a24b8911dd7147df6ff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8265</th>\n",
       "      <td>These incredible photographs  appear to captur...</td>\n",
       "      <td>Cloud formation before the red dusk sky resemb...</td>\n",
       "      <td>b07c92c4891209b7e43ae2bbb851905b6169ad2e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11389</th>\n",
       "      <td>Prince Harry will go on tough bush patrols and...</td>\n",
       "      <td>Details of Prince Harry's Australian deploymen...</td>\n",
       "      <td>fd3a7a63c35a929ab9ab228def89fa73591892d0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>In cities that are as well-known for their bur...</td>\n",
       "      <td>Hotels around the world are now hiring top des...</td>\n",
       "      <td>1f25f86d975211c64655e6e8802651fc6e66a83b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10527</th>\n",
       "      <td>Not a day goes by that 14-year-old Jonathan Pi...</td>\n",
       "      <td>Jonathan Pitre has deep blistering wounds all ...</td>\n",
       "      <td>e80a5379065c0cc87670ef2ce3f3f378904492a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11291</th>\n",
       "      <td>Model and actress Sulinh Lafontaine is not a d...</td>\n",
       "      <td>Sulinh Lafontaine presented herself as a dared...</td>\n",
       "      <td>fab2ad3269eef684b7da01efe151b4b1ce6a2596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>The NSW State Emergency Service (SES) are warn...</td>\n",
       "      <td>NSW SES warns scammers are phoning people clai...</td>\n",
       "      <td>7ead02c636ed9db09cdb973b943a61587ef627e7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>Staff attorneys at the U.S. Justice Department...</td>\n",
       "      <td>Attorneys at the U.S. Justice Department may r...</td>\n",
       "      <td>3f2f668a7dce47fe7dd7ff57a1e796245a7cb754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5275</th>\n",
       "      <td>Lesley Conman's daughter Abbie, 12, was sent s...</td>\n",
       "      <td>Young girls were sent sexualised Facebook mess...</td>\n",
       "      <td>64d847a2f06d277f895e41e5f751c6a8fb76f136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>Canadian pop sensation Justin Bieber is will c...</td>\n",
       "      <td>Justin Bieber is a good friend of Floyd Maywea...</td>\n",
       "      <td>1dc22202efb4e51fb9487ccf82524ab9eb2de7b5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 article  \\\n",
       "6158   A woman who already has four children is set t...   \n",
       "8265   These incredible photographs  appear to captur...   \n",
       "11389  Prince Harry will go on tough bush patrols and...   \n",
       "2386   In cities that are as well-known for their bur...   \n",
       "10527  Not a day goes by that 14-year-old Jonathan Pi...   \n",
       "11291  Model and actress Sulinh Lafontaine is not a d...   \n",
       "6297   The NSW State Emergency Service (SES) are warn...   \n",
       "3686   Staff attorneys at the U.S. Justice Department...   \n",
       "5275   Lesley Conman's daughter Abbie, 12, was sent s...   \n",
       "2336   Canadian pop sensation Justin Bieber is will c...   \n",
       "\n",
       "                                              highlights  \\\n",
       "6158   Nadine Crooks, 33, has four children aged 18 y...   \n",
       "8265   Cloud formation before the red dusk sky resemb...   \n",
       "11389  Details of Prince Harry's Australian deploymen...   \n",
       "2386   Hotels around the world are now hiring top des...   \n",
       "10527  Jonathan Pitre has deep blistering wounds all ...   \n",
       "11291  Sulinh Lafontaine presented herself as a dared...   \n",
       "6297   NSW SES warns scammers are phoning people clai...   \n",
       "3686   Attorneys at the U.S. Justice Department may r...   \n",
       "5275   Young girls were sent sexualised Facebook mess...   \n",
       "2336   Justin Bieber is a good friend of Floyd Maywea...   \n",
       "\n",
       "                                             id  \n",
       "6158   7b1bd79278c2ced9eb271a24b8911dd7147df6ff  \n",
       "8265   b07c92c4891209b7e43ae2bbb851905b6169ad2e  \n",
       "11389  fd3a7a63c35a929ab9ab228def89fa73591892d0  \n",
       "2386   1f25f86d975211c64655e6e8802651fc6e66a83b  \n",
       "10527  e80a5379065c0cc87670ef2ce3f3f378904492a3  \n",
       "11291  fab2ad3269eef684b7da01efe151b4b1ce6a2596  \n",
       "6297   7ead02c636ed9db09cdb973b943a61587ef627e7  \n",
       "3686   3f2f668a7dce47fe7dd7ff57a1e796245a7cb754  \n",
       "5275   64d847a2f06d277f895e41e5f751c6a8fb76f136  \n",
       "2336   1dc22202efb4e51fb9487ccf82524ab9eb2de7b5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence = df.article.values\n",
    "train_target = df.highlights.values\n",
    "\n",
    "\n",
    "num_data_points = 500\n",
    "train_sentence = list(train_sentence)[:num_data_points]\n",
    "train_target = list(train_target)[:num_data_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_encoding = tokenizer(train_sentence, return_tensors='pt', padding=True, truncation = True, max_length=500)\n",
    "summary_encoding = tokenizer(train_target, return_tensors='pt', padding=True,truncation = True, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_input_ids = article_encoding['input_ids']\n",
    "article_attention_mask = article_encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_input_ids = summary_encoding['input_ids']\n",
    "summary_attention_mask = summary_encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_data = TensorDataset(input_ids, input_mask, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader_clf = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_data = TensorDataset(article_input_ids, article_attention_mask,\\\n",
    "                           summary_input_ids, summary_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bleu(reference, candidate):\n",
    "    score1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))    \n",
    "    return score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1,c2,c3 = next(iter(train_dataloader_clf)) \n",
    "c1 = c1.cuda() \n",
    "c2 = c2.cuda() \n",
    "c3 = c3.cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1,b2,b3,b4 = next(iter(train_dataloader)) \n",
    "b1 = b1.cuda() \n",
    "b2 = b2.cuda() \n",
    "b3 = b3.cuda() \n",
    "b4 = b4.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Catania, Sicily (CNN)We are at the beginning of a massive and mounting crisis with no solution in sight. Perhaps that\\'s incorrect. The migrant crisis that has suddenly drawn hundreds of journalists to Sicily has been brewing for years, but in the past 10 days, with as many as 1,600 deaths in the Mediterranean, suddenly minds are focused -- for now. Almost exactly four years ago, in Libya, I caught, perhaps, a glimpse of what was to come. It was late at night in the besieged city of Misrata. Hundreds of African migrants were caught between the Libyan civil war (back then some optimistically called it a \"revolution\") and the deep blue sea. They had come to Misrata from Ghana, Nigeria and elsewhere, hoping to board rickety boats to cross the sea to Europe. They had been pinned down under sporadic shelling from government forces, but weren\\'t welcome by the rebels who controlled the city. They appealed to us to help them escape. We could do nothing, but they may have eventually found their way out when the fighting subsided. The fall of Libyan leader Moammar Gadhafi\\'s regime, which we reporters covered so avidly, was followed by chaos, which we in the news media largely neglected, focused as we journalists were on the next catastrophe, the Syrian civil war. In that chaos, the business of human trafficking has boomed. And now that boom in human misery is coming in waves to the shores of Italy. The focus today is on those lost at sea. Aware of the tragedy underway, however, Italians are alarmed at the prospect that this year alone as many as a million migrants could arrive in Europe, according to one European Union official. That is certainly the case in the Sicilian port of Catania, where many migrants arrive. The city\\'s mayor, Enzo Bianco, insists city residents bear no ill will toward the migrants, but says Catania, and Sicily cannot absorb the ever-growing numbers. The rest of Europe must help carry the burden. \"If something serious isn\\'t done,\" he warns, \"dramas like these will be repeated. This problem will not be resolved by hiding our heads in the sand.\" Increasingly, some Italians are losing their patience. Two northern regions, Veneto and Valle d\\'Aosta, have declared they will no longer accept new migrants. The rightist Lega Nord has made opposition to new migrants a pillar of its party'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(b1[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hundreds of desperate migrants have died attempting to cross the Mediterranean in recent says.\\nAnd Italians are alarmed that this year as many as a million migrants could arrive in Europe.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(b3[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_out,*sentiments = merge_model(b1, b2, b3, b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hundreds of journalists African have been in to cross the Mediterranean. recent days Italian\\nItaly now are alarmed at this year alone many as a million migrants could arrive in Europe.\\nTheItaly Italian the the the Italian the the the theItaly Italy Italy the the the theItaly the the the the the the the the the the the the the the the the the the the the Mediterranean thely the the the the thely the thely the'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(summary_out.logits.argmax(dim = -1)[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_model.load_state_dict(torch.load('BART_classifier_final_MSE_eqcost.pt'))\n",
    "merge_model = merge_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_model.load_state_dict(torch.load('Sai_Test/classifier_model.pt'))\n",
    "sent_model = sent_model.cuda()\n",
    "sent_model = sent_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/home/11/811/adharask/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/datasets/home/11/811/adharask/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/datasets/home/11/811/adharask/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1586451536859683 0.21263009071350097\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "ss = []\n",
    "\n",
    "for b1, b2, b3, b4 in train_dataloader:\n",
    "    b1 = b1.cuda() \n",
    "    b2 = b2.cuda() \n",
    "    b3 = b3.cuda() \n",
    "    b4 = b4.cuda()\n",
    "    summary_out,*sentiments = merge_model(b1, b2, b3, b4)\n",
    "    ss.append(torch.abs(sent_model(summary_out.logits.argmax(dim = -1)) - sent_model(b1)/6).mean().item())\n",
    "    \n",
    "    for i in range(b3.shape[0]):\n",
    "        summary_gt = tokenizer.decode(b3[i], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        summary_pred = tokenizer.decode(summary_out.logits.argmax(dim = -1)[i], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        temp.append(get_bleu(summary_pred, summary_gt))\n",
    "        \n",
    "print(np.array(temp).mean(), np.array(ss).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_model.load_state_dict(torch.load('BART_classifier_final_MSE.pt'))\n",
    "merge_model = merge_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15852145927668804 0.0426627171933651\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "ss = []\n",
    "\n",
    "for b1, b2, b3, b4 in train_dataloader:\n",
    "    b1 = b1.cuda() \n",
    "    b2 = b2.cuda() \n",
    "    b3 = b3.cuda() \n",
    "    b4 = b4.cuda()\n",
    "    summary_out,*sentiments = merge_model(b1, b2, b3, b4)\n",
    "    ss.append(torch.abs(sent_model(summary_out.logits.argmax(dim = -1)) - sent_model(b1)/6).mean().item())\n",
    "    \n",
    "    for i in range(b3.shape[0]):\n",
    "        summary_gt = tokenizer.decode(b3[i], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        summary_pred = tokenizer.decode(summary_out.logits.argmax(dim = -1)[i], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        temp.append(get_bleu(summary_pred, summary_gt))\n",
    "        \n",
    "print(np.array(temp).mean(), np.array(ss).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

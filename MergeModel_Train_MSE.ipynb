{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "from utils.file_utils import *\n",
    "from datasets import list_datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from IPython import get_ipython\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from models.MergeModel import MergeModel\n",
    "from models.ClassifierModel import ClassifierModel\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartForSequenceClassification\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "get_ipython().run_line_magic('autoreload', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50265"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 11,490\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>James McClean's reaction said it all. As Scott...</td>\n",
       "      <td>Wigan twice came from behind to force a draw ....</td>\n",
       "      <td>089cff49c55c17aa967b5d2ae4520c111855485c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>(CNN)When Les Moonves sits down at a restauran...</td>\n",
       "      <td>Gabriel Salvador set up an initial meeting bet...</td>\n",
       "      <td>a29bf087eb57352a72ba0227bc554960acde24a9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>(CNN)He wouldn't give his name. But the name t...</td>\n",
       "      <td>The sheriff says a \"big mistake\" contributed t...</td>\n",
       "      <td>4dea716446fc10eb9c9848be963345528a67b515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6386</th>\n",
       "      <td>The state of Oregon on Friday released 94,000 ...</td>\n",
       "      <td>Cylvia Hayes allegedly used her relationship w...</td>\n",
       "      <td>8178f2b8be386166d5ea0a78a72fa571870e01be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7331</th>\n",
       "      <td>A farmer from eastern China has found himself ...</td>\n",
       "      <td>Farmer from eastern China confesses he's puzzl...</td>\n",
       "      <td>98f1f69a4a766df0631c46511ee1b1200c524eec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8491</th>\n",
       "      <td>An injured and diseased Husky has been picked ...</td>\n",
       "      <td>The Husky was injured and diseased when found ...</td>\n",
       "      <td>b5a4eac7cb1990b59ec0bd63b6791f77b34ebd6a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7054</th>\n",
       "      <td>Many people will know the feeling of spending ...</td>\n",
       "      <td>Fifi M. Maacaron, 36, from Newport News, Virgi...</td>\n",
       "      <td>92258c751cea2255373fce285bba4047858c85ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7108</th>\n",
       "      <td>A 15-year-old boy has been arrested for allege...</td>\n",
       "      <td>DeShawn Isabelle allegedly punched the woman i...</td>\n",
       "      <td>932c3eda4f4fd057d9fc2b85bf9853d3822b2053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11194</th>\n",
       "      <td>When it comes to the Coachella festival, a num...</td>\n",
       "      <td>In the searing California heat, many jumped on...</td>\n",
       "      <td>f840ef7add6cd4f124df461327a9473e976aa95a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>There can't always be a TV camera rolling when...</td>\n",
       "      <td>Sketch mocked network's coverage of air disast...</td>\n",
       "      <td>0b9d1cd711647793a9fa007f2892cd3ac59e1227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 article  \\\n",
       "1473   James McClean's reaction said it all. As Scott...   \n",
       "683    (CNN)When Les Moonves sits down at a restauran...   \n",
       "350    (CNN)He wouldn't give his name. But the name t...   \n",
       "6386   The state of Oregon on Friday released 94,000 ...   \n",
       "7331   A farmer from eastern China has found himself ...   \n",
       "8491   An injured and diseased Husky has been picked ...   \n",
       "7054   Many people will know the feeling of spending ...   \n",
       "7108   A 15-year-old boy has been arrested for allege...   \n",
       "11194  When it comes to the Coachella festival, a num...   \n",
       "1588   There can't always be a TV camera rolling when...   \n",
       "\n",
       "                                              highlights  \\\n",
       "1473   Wigan twice came from behind to force a draw ....   \n",
       "683    Gabriel Salvador set up an initial meeting bet...   \n",
       "350    The sheriff says a \"big mistake\" contributed t...   \n",
       "6386   Cylvia Hayes allegedly used her relationship w...   \n",
       "7331   Farmer from eastern China confesses he's puzzl...   \n",
       "8491   The Husky was injured and diseased when found ...   \n",
       "7054   Fifi M. Maacaron, 36, from Newport News, Virgi...   \n",
       "7108   DeShawn Isabelle allegedly punched the woman i...   \n",
       "11194  In the searing California heat, many jumped on...   \n",
       "1588   Sketch mocked network's coverage of air disast...   \n",
       "\n",
       "                                             id  \n",
       "1473   089cff49c55c17aa967b5d2ae4520c111855485c  \n",
       "683    a29bf087eb57352a72ba0227bc554960acde24a9  \n",
       "350    4dea716446fc10eb9c9848be963345528a67b515  \n",
       "6386   8178f2b8be386166d5ea0a78a72fa571870e01be  \n",
       "7331   98f1f69a4a766df0631c46511ee1b1200c524eec  \n",
       "8491   b5a4eac7cb1990b59ec0bd63b6791f77b34ebd6a  \n",
       "7054   92258c751cea2255373fce285bba4047858c85ee  \n",
       "7108   932c3eda4f4fd057d9fc2b85bf9853d3822b2053  \n",
       "11194  f840ef7add6cd4f124df461327a9473e976aa95a  \n",
       "1588   0b9d1cd711647793a9fa007f2892cd3ac59e1227  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence = df.article.values\n",
    "train_target = df.highlights.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_points = 10000\n",
    "train_sentence = list(train_sentence[:num_data_points])\n",
    "train_target = list(train_target[:num_data_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_encoding = tokenizer(train_sentence, return_tensors='pt', padding=True, truncation = True, max_length=500)\n",
    "summary_encoding = tokenizer(train_target, return_tensors='pt', padding=True,truncation = True, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_input_ids = article_encoding['input_ids']\n",
    "article_attention_mask = article_encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_input_ids = summary_encoding['input_ids']\n",
    "summary_attention_mask = summary_encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 500]) torch.Size([10000, 500])\n"
     ]
    }
   ],
   "source": [
    "print(article_input_ids.shape, article_attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 100]) torch.Size([10000, 100])\n"
     ]
    }
   ],
   "source": [
    "print(summary_input_ids.shape, summary_attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_data = TensorDataset(article_input_ids, article_attention_mask,\\\n",
    "                           summary_input_ids, summary_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(lm_logits, labels):\n",
    "    loss_fct = CrossEntropyLoss(ignore_index = tokenizer.pad_token_id)\n",
    "    loss = loss_fct(lm_logits.view(-1, vocab_size), labels.view(-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_MSE(sentiment1, sentiment2):\n",
    "    mse_loss = nn.MSELoss()    \n",
    "    s1 = F.softmax(sentiment1)\n",
    "    s2 = F.softmax(sentiment2)    \n",
    "    return mse_loss(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'ClassifierModel.ClassifierModel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "sent_model = torch.load('experiment/classifier/classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierModel(\n",
       "  (embedding): Embedding_(\n",
       "    (embedding): Embedding(50265, 64)\n",
       "  )\n",
       "  (lstm): LSTM(64, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (fc1): Linear(in_features=512, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_model = summary_model.cuda()\n",
    "senti_model = sent_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_dim = 64\n",
    "# out_dim = 2\n",
    "# n_layers = 4\n",
    "# hidden_size = 512\n",
    "merge_model = MergeModel(summary_model, senti_model,freeze_sentiment=False)\n",
    "model_name = 'MSE_softmax_regularized_1e-3_hybrid'\n",
    "model_dir = './experiment'\n",
    "model_path = os.path.join(model_dir,model_name)\n",
    "epochs  = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "#     'embedding_dim': embedding_dim,\n",
    "#     'out_dim': out_dim,\n",
    "#     'n_layers': n_layers,\n",
    "#     'hidden_size': hidden_size,\n",
    "    'model_name': model_name,\n",
    "    'epochs':epochs,\n",
    "    'lambda': 1e-3,\n",
    "    'freeze_at': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False, model_dir='./experiment',optimizer='ADAM',config = None):\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    min_val_loss = np.inf\n",
    "    \n",
    "    model_name = config['model_name']\n",
    "    print(f\"Start training for Model {model_name}...\\n\")\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(os.path.join(model_dir,model_name)):\n",
    "        os.mkdir(os.path.join(model_dir,model_name))\n",
    "    model_path = os.path.join(model_dir,model_name)\n",
    "    write_to_file_in_dir(model_path, 'config.json', config)\n",
    "    \n",
    "    train_log =  'train_log.txt'\n",
    "    write_string_train = f\"Epoch, Cross_Entropy_Loss, MSE_Loss, Total_Loss \"\n",
    "    log_to_file_in_dir(model_path, train_log, write_string_train)\n",
    "\n",
    "    if evaluation:\n",
    "        val_log = 'val_log.txt'\n",
    "        write_string_val = f\"Epoch, Val_Loss, Val_Acc\"\n",
    "        log_to_file_in_dir(model_path, val_log, write_string_val)\n",
    "    \n",
    "    if optimizer == 'ADAM':\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "    else:    \n",
    "        optimizer = torch.optim.SGD(model.parameters(),1e-3,momentum=0.9,weight_decay=0.01)\n",
    "    \n",
    "    for epoch_i in range(epochs):\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "        model.train()\n",
    "        \n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            model.train()\n",
    "            batch_counts +=1\n",
    "            \n",
    "            batch[0] = batch[0].cuda()\n",
    "            batch[1] = batch[1].cuda()\n",
    "            batch[2] = batch[2].cuda()\n",
    "            batch[3] = batch[3].cuda()\n",
    "            \n",
    "            model.zero_grad()\n",
    "                \n",
    "            \n",
    "            summary_out,*sentiments = merge_model(batch[0],batch[1], batch[2], batch[3])\n",
    "        \n",
    "            loss1 = loss_fn(summary_out.logits, batch[2])\n",
    "            if epoch_i-1 < config['freeze_at']:\n",
    "                loss2 = softmax_MSE(sentiments[0], sentiments[1])\n",
    "                loss = loss1 + config['lambda']*loss2\n",
    "            else:\n",
    "                model.freeze_sentiment = True\n",
    "                loss2 = 0\n",
    "                loss = loss1\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            write_string_train = f\"{epoch_i}, {loss1.item()}, {loss2.item()}, {loss.item()}\"\n",
    "            log_to_file_in_dir(model_path, train_log, write_string_train)\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if (step % 100 == 0 and step != 0):\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "                print(\"-\"*70)\n",
    "\n",
    "        if ((epoch_i %20 ==0) and (epoch_i != 0)) or (epoch_i==epochs-1):\n",
    "            if evaluation == True:\n",
    "                val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "                val_losses.append(val_loss)\n",
    "                val_accs.append(val_accuracy)\n",
    "                \n",
    "                write_string_val = f\"{epoch_i}, {val_loss}, {val_accuracy}\"\n",
    "                log_to_file_in_dir(model_path, val_log, write_string_val)\n",
    "                \n",
    "                time_elapsed = time.time() - t0_epoch\n",
    "                \n",
    "                if val_loss < min_val_loss:\n",
    "                    min_val_loss = val_loss\n",
    "                    \n",
    "                    torch.save(model, os.path.join(model_path, f'{model_name}.pt'))\n",
    "                    \n",
    "                print(f\"{epoch_i + 1:^7} | {'-':^7} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "        \n",
    "    torch.save(model, os.path.join(model_path,f'{model_name}_final.pt'))\n",
    "        \n",
    "    return  train_losses, train_accs, val_losses,val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for Model MSE_softmax_regularized_1e-3_hybrid...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1    |   100   |   8.660300   |     -      |     -     |   56.51  \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-0b2e5f78b919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ADAM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-7984583e53eb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, epochs, evaluation, model_dir, optimizer, config)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stats = train(merge_model, train_dataloader, val_dataloader=None, epochs=epochs, evaluation=False,  config=config, optimizer='ADAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_accs, val_losses,val_accs = stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(train_losses)), np.array(train_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1,b2,b3,b4 = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = merge_model(b1.cuda(), b2.cuda(), b3.cuda(), b4.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_ex = b1[0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_ex = b3[0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(b1_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(b3_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_summary = out[0].logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(torch.argmax(b1_summary, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_arg = out[0].logits.argmax(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[1][0], out[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b1,b2,b3,b4 = next(iter(train_dataloader))\n",
    "b1 = b1.cuda()\n",
    "b2 = b2.cuda()\n",
    "b3 = b3.cuda()\n",
    "b4 = b4.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b1.shape, b2.shape, b3.shape, b4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z1 = torch.nn.Parameter(torch.ones_like(b1).float()).long()\n",
    "z2 = torch.ones_like(b2)\n",
    "\n",
    "z1_dash = z1 + 5\n",
    "z2_dash = z2 + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t = summary_model(b1, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t.logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t_dash = merge_model(b1, b2, b3,b4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t_dash[0].logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss = mse_loss(t_dash[1], t_dash[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(torch.autograd.grad(loss,merge_model.summary_model.parameters(), retain_graph=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

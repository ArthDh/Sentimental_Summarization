{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "from utils.file_utils import *\n",
    "from datasets import list_datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from IPython import get_ipython\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from models.MergeModel import MergeModel\n",
    "from models.ClassifierModel import ClassifierModel\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartForSequenceClassification\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "get_ipython().run_line_magic('autoreload', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50265"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 11,490\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5631</th>\n",
       "      <td>Dozens of staff at Manchester United's Megasto...</td>\n",
       "      <td>Mascot among dozen of staff concerned about th...</td>\n",
       "      <td>6dd7930667c3ac55ba6ffd382a7637ba5e33e065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5879</th>\n",
       "      <td>Ahead of a weekend featuring drama from the Ba...</td>\n",
       "      <td>Reading face Arsenal at Wembley on Saturday in...</td>\n",
       "      <td>74169a8577c0e13c81559011439392fecb8fc6c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>(CNN)[Breaking news update, posted at 5:22 p.m...</td>\n",
       "      <td>Military has not confirmed if any rescued girl...</td>\n",
       "      <td>777ad85a86e8e8675454e243517afa2689f81575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8859</th>\n",
       "      <td>Bearing in mind he’s a dog, Don the border col...</td>\n",
       "      <td>The bizarre incident happened on M74 near Abin...</td>\n",
       "      <td>be8a11519f9001b83610bc1e39ef476617921054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>(CNN)Saturday at the Masters, like any PGA tou...</td>\n",
       "      <td>Jordan Spieth holds lead in 2015 Masters .\\nSt...</td>\n",
       "      <td>f555b81fb888354a9a83ba9acc1bdb18791441ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101</th>\n",
       "      <td>An Australian teenager has joined the puffy po...</td>\n",
       "      <td>Aussie girl joins #kyliejennerchallenge curren...</td>\n",
       "      <td>ac351092890e1f82ee66d97139d4aaa24f6a7131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>A shocking new video appearing to show at leas...</td>\n",
       "      <td>Video seems to show militants in Libya holding...</td>\n",
       "      <td>02e7ee52406518338ea1d184af26d107a3c0ab7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9423</th>\n",
       "      <td>We’ve all been there: you hear a catchy song a...</td>\n",
       "      <td>Reading scientists say chewing gum helps you f...</td>\n",
       "      <td>cc3bc57fb6a2e29054d13933fbc5f2e0a63e3d79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3635</th>\n",
       "      <td>England suffered an injury scare at the start ...</td>\n",
       "      <td>Broad slipped in his delivery stride and was l...</td>\n",
       "      <td>3e27e82895df660541c19e828d19a68023a04034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>(CNN)Andrew Getty, one of the heirs to billion...</td>\n",
       "      <td>Andrew Getty's death appears to be from natura...</td>\n",
       "      <td>0d3c8c276d079c4c225f034c69aa024cdab7869d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                article  \\\n",
       "5631  Dozens of staff at Manchester United's Megasto...   \n",
       "5879  Ahead of a weekend featuring drama from the Ba...   \n",
       "511   (CNN)[Breaking news update, posted at 5:22 p.m...   \n",
       "8859  Bearing in mind he’s a dog, Don the border col...   \n",
       "1023  (CNN)Saturday at the Masters, like any PGA tou...   \n",
       "8101  An Australian teenager has joined the puffy po...   \n",
       "1201  A shocking new video appearing to show at leas...   \n",
       "9423  We’ve all been there: you hear a catchy song a...   \n",
       "3635  England suffered an injury scare at the start ...   \n",
       "63    (CNN)Andrew Getty, one of the heirs to billion...   \n",
       "\n",
       "                                             highlights  \\\n",
       "5631  Mascot among dozen of staff concerned about th...   \n",
       "5879  Reading face Arsenal at Wembley on Saturday in...   \n",
       "511   Military has not confirmed if any rescued girl...   \n",
       "8859  The bizarre incident happened on M74 near Abin...   \n",
       "1023  Jordan Spieth holds lead in 2015 Masters .\\nSt...   \n",
       "8101  Aussie girl joins #kyliejennerchallenge curren...   \n",
       "1201  Video seems to show militants in Libya holding...   \n",
       "9423  Reading scientists say chewing gum helps you f...   \n",
       "3635  Broad slipped in his delivery stride and was l...   \n",
       "63    Andrew Getty's death appears to be from natura...   \n",
       "\n",
       "                                            id  \n",
       "5631  6dd7930667c3ac55ba6ffd382a7637ba5e33e065  \n",
       "5879  74169a8577c0e13c81559011439392fecb8fc6c3  \n",
       "511   777ad85a86e8e8675454e243517afa2689f81575  \n",
       "8859  be8a11519f9001b83610bc1e39ef476617921054  \n",
       "1023  f555b81fb888354a9a83ba9acc1bdb18791441ca  \n",
       "8101  ac351092890e1f82ee66d97139d4aaa24f6a7131  \n",
       "1201  02e7ee52406518338ea1d184af26d107a3c0ab7c  \n",
       "9423  cc3bc57fb6a2e29054d13933fbc5f2e0a63e3d79  \n",
       "3635  3e27e82895df660541c19e828d19a68023a04034  \n",
       "63    0d3c8c276d079c4c225f034c69aa024cdab7869d  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence = df.article.values\n",
    "train_target = df.highlights.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_points = 10000\n",
    "train_sentence = list(train_sentence[:num_data_points])\n",
    "train_target = list(train_target[:num_data_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_encoding = tokenizer(train_sentence, return_tensors='pt', padding=True, truncation = True, max_length=500)\n",
    "summary_encoding = tokenizer(train_target, return_tensors='pt', padding=True,truncation = True, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_input_ids = article_encoding['input_ids']\n",
    "article_attention_mask = article_encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_input_ids = summary_encoding['input_ids']\n",
    "summary_attention_mask = summary_encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 500]) torch.Size([10000, 500])\n"
     ]
    }
   ],
   "source": [
    "print(article_input_ids.shape, article_attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 100]) torch.Size([10000, 100])\n"
     ]
    }
   ],
   "source": [
    "print(summary_input_ids.shape, summary_attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_data = TensorDataset(article_input_ids, article_attention_mask,\\\n",
    "                           summary_input_ids, summary_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(lm_logits, labels):\n",
    "    loss_fct = CrossEntropyLoss(ignore_index = tokenizer.pad_token_id)\n",
    "    loss = loss_fct(lm_logits.view(-1, vocab_size), labels.view(-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_MSE(sentiment1, sentiment2):\n",
    "    mse_loss = nn.MSELoss()    \n",
    "    s1 = F.softmax(sentiment1)\n",
    "    s2 = F.softmax(sentiment2)    \n",
    "    return mse_loss(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'ClassifierModel.ClassifierModel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "sent_model = torch.load('experiment/classifier/classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierModel(\n",
       "  (embedding): Embedding_(\n",
       "    (embedding): Embedding(50265, 64)\n",
       "  )\n",
       "  (lstm): LSTM(64, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (fc1): Linear(in_features=512, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_model = summary_model.cuda()\n",
    "senti_model = sent_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_dim = 64\n",
    "# out_dim = 2\n",
    "# n_layers = 4\n",
    "# hidden_size = 512\n",
    "merge_model = MergeModel(summary_model, senti_model,freeze_sentiment=False)\n",
    "model_name = 'MSE_softmax_regularized_1e-3'\n",
    "model_dir = './experiment'\n",
    "model_path = os.path.join(model_dir,model_name)\n",
    "epochs  = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "#     'embedding_dim': embedding_dim,\n",
    "#     'out_dim': out_dim,\n",
    "#     'n_layers': n_layers,\n",
    "#     'hidden_size': hidden_size,\n",
    "    'model_name': model_name,\n",
    "    'epochs':epochs,\n",
    "    'lambda': 1e-3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False, model_dir='./experiment',optimizer='ADAM',config = None):\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    min_val_loss = np.inf\n",
    "    \n",
    "    model_name = config['model_name']\n",
    "    print(f\"Start training for Model {model_name}...\\n\")\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(os.path.join(model_dir,model_name)):\n",
    "        os.mkdir(os.path.join(model_dir,model_name))\n",
    "    model_path = os.path.join(model_dir,model_name)\n",
    "    write_to_file_in_dir(model_path, 'config.json', config)\n",
    "    \n",
    "    train_log =  'train_log.txt'\n",
    "    write_string_train = f\"Epoch, Cross_Entropy_Loss, MSE_Loss, Total_Loss \"\n",
    "    log_to_file_in_dir(model_path, train_log, write_string_train)\n",
    "\n",
    "    if evaluation:\n",
    "        val_log = 'val_log.txt'\n",
    "        write_string_val = f\"Epoch, Val_Loss, Val_Acc\"\n",
    "        log_to_file_in_dir(model_path, val_log, write_string_val)\n",
    "    \n",
    "    if optimizer == 'ADAM':\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "    else:    \n",
    "        optimizer = torch.optim.SGD(model.parameters(),1e-3,momentum=0.9,weight_decay=0.01)\n",
    "    \n",
    "    for epoch_i in range(epochs):\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "        model.train()\n",
    "        \n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            model.train()\n",
    "            batch_counts +=1\n",
    "            \n",
    "            batch[0] = batch[0].cuda()\n",
    "            batch[1] = batch[1].cuda()\n",
    "            batch[2] = batch[2].cuda()\n",
    "            batch[3] = batch[3].cuda()\n",
    "            \n",
    "            model.zero_grad()\n",
    "            \n",
    "            summary_out,*sentiments = merge_model(batch[0],batch[1], batch[2], batch[3])\n",
    "        \n",
    "            loss1 = loss_fn(summary_out.logits, batch[2])\n",
    "            loss2 = softmax_MSE(sentiments[0], sentiments[1])\n",
    "\n",
    "            loss = loss1 + 1e-3*loss2\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            write_string_train = f\"{epoch_i}, {loss1.item()}, {loss2.item()}, {loss.item()}\"\n",
    "            log_to_file_in_dir(model_path, train_log, write_string_train)\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if (step % 100 == 0 and step != 0):\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "                print(\"-\"*70)\n",
    "\n",
    "        if ((epoch_i %20 ==0) and (epoch_i != 0)) or (epoch_i==epochs-1):\n",
    "            if evaluation == True:\n",
    "                val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "                val_losses.append(val_loss)\n",
    "                val_accs.append(val_accuracy)\n",
    "                \n",
    "                write_string_val = f\"{epoch_i}, {val_loss}, {val_accuracy}\"\n",
    "                log_to_file_in_dir(model_path, val_log, write_string_val)\n",
    "                \n",
    "                time_elapsed = time.time() - t0_epoch\n",
    "                \n",
    "                if val_loss < min_val_loss:\n",
    "                    min_val_loss = val_loss\n",
    "                    \n",
    "                    torch.save(model, os.path.join(model_path, f'{model_name}.pt'))\n",
    "                    \n",
    "                print(f\"{epoch_i + 1:^7} | {'-':^7} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "        \n",
    "    torch.save(model, os.path.join(model_path,f'{model_name}_final.pt'))\n",
    "        \n",
    "    return  train_losses, train_accs, val_losses,val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for Model MSE_softmax_regularized_1e-3...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1    |   100   |  12.255563   |     -      |     -     |   56.64  \n",
      "----------------------------------------------------------------------\n",
      "   1    |   200   |   9.884003   |     -      |     -     |   55.85  \n",
      "----------------------------------------------------------------------\n",
      "   1    |   300   |   9.168384   |     -      |     -     |   55.71  \n",
      "----------------------------------------------------------------------\n",
      "   1    |   400   |   8.635020   |     -      |     -     |   56.04  \n",
      "----------------------------------------------------------------------\n",
      "   1    |   500   |   8.156194   |     -      |     -     |   55.76  \n",
      "----------------------------------------------------------------------\n",
      "   1    |   600   |   7.948882   |     -      |     -     |   55.89  \n",
      "----------------------------------------------------------------------\n",
      "   1    |   700   |   7.811362   |     -      |     -     |   55.90  \n",
      "----------------------------------------------------------------------\n",
      "   1    |   800   |   7.765304   |     -      |     -     |   55.91  \n",
      "----------------------------------------------------------------------\n",
      "   1    |   900   |   7.733743   |     -      |     -     |   56.10  \n",
      "----------------------------------------------------------------------\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   100   |   7.604195   |     -      |     -     |   56.45  \n",
      "----------------------------------------------------------------------\n",
      "   2    |   200   |   7.622666   |     -      |     -     |   56.03  \n",
      "----------------------------------------------------------------------\n",
      "   2    |   300   |   7.597181   |     -      |     -     |   55.74  \n",
      "----------------------------------------------------------------------\n",
      "   2    |   400   |   7.585563   |     -      |     -     |   56.15  \n",
      "----------------------------------------------------------------------\n",
      "   2    |   500   |   7.583472   |     -      |     -     |   55.89  \n",
      "----------------------------------------------------------------------\n",
      "   2    |   600   |   7.599850   |     -      |     -     |   55.84  \n",
      "----------------------------------------------------------------------\n",
      "   2    |   700   |   7.580355   |     -      |     -     |   55.80  \n",
      "----------------------------------------------------------------------\n",
      "   2    |   800   |   7.560564   |     -      |     -     |   55.78  \n",
      "----------------------------------------------------------------------\n",
      "   2    |   900   |   7.562145   |     -      |     -     |   55.86  \n",
      "----------------------------------------------------------------------\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   3    |   100   |   7.584163   |     -      |     -     |   56.59  \n",
      "----------------------------------------------------------------------\n",
      "   3    |   200   |   7.562575   |     -      |     -     |   55.81  \n",
      "----------------------------------------------------------------------\n",
      "   3    |   300   |   7.552161   |     -      |     -     |   55.97  \n",
      "----------------------------------------------------------------------\n",
      "   3    |   400   |   7.548511   |     -      |     -     |   56.17  \n",
      "----------------------------------------------------------------------\n",
      "   3    |   500   |   7.555219   |     -      |     -     |   56.04  \n",
      "----------------------------------------------------------------------\n",
      "   3    |   600   |   7.564937   |     -      |     -     |   55.96  \n",
      "----------------------------------------------------------------------\n",
      "   3    |   700   |   7.554170   |     -      |     -     |   55.90  \n",
      "----------------------------------------------------------------------\n",
      "   3    |   800   |   7.935329   |     -      |     -     |   55.97  \n",
      "----------------------------------------------------------------------\n",
      "   3    |   900   |   7.580407   |     -      |     -     |   56.20  \n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "stats = train(merge_model, train_dataloader, val_dataloader=None, epochs=epochs, evaluation=False,  config=config, optimizer='ADAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_accs, val_losses,val_accs = stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc43967de50>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3xUVd4G8OeXQkIJPXRCQpdeAoIigsDSdMXd9VVfC2tZfXfVXd11FTsqIqvY1rK7qIhlZV13sQFKb1INJXRIIICBdCC9zpz3j7kzmZlMkslk2mGe7+fDJzN37tz7u7nhmTPnnnuvKKVARET6CQt0AURE5BkGOBGRphjgRESaYoATEWmKAU5EpKkIf66sffv2Kj4+3p+rJCLS3u7du3OVUrHO0/0a4PHx8UhKSvLnKomItCcip11NZxcKEZGmGOBERJpigBMRaYoBTkSkKQY4EZGmGOBERJpigBMRaUqrAC+tMGHZnnTwErhERH4+kaexnl9+GEt3nUHnVk0xtle7QJdDRBRQWrXAswvKAABF5VUBroSIKPC0CnARy092oRARaRbggAS6ACKioKFZgFuw/U1EpFmAV3ehBLYOIqJgoFWAExFRNQY4EZGmtArw6kOY7EMhItIrwNkHTkRko1eAcxghEZGNVgFuxQY4EZFmAc4uFCKialoGOBERuRHgIrJYRLJF5KDdtGEiskNE9olIkoiM9m2ZRETkzJ0W+BIA05ymvQzgOaXUMADPGM/9RrEXnIio/gBXSm0GcN55MoCWxuNWAM55uS6XrKNQ2AdOROT5DR0eArBKRBbC8iFwRW0zisi9AO4FgLi4OA9XZ12Y5Qfzm4jI84OYvwXwsFKqO4CHAXxQ24xKqUVKqUSlVGJsbKyHq7PgMUwiomqeBvhsAMuMx18A8OtBTN7QgYjI8wA/B+Bq4/E1AFK8U07dhOMIiYhs6u0DF5GlACYAaC8i6QCeBfAbAG+KSASAMhh93ERE5D/1BrhS6pZaXhrp5VqIiKgB9DoT0/jJLnAiIt0C3DaMkAlORKRXgAe6ACKiIKJVgBMRUTUtA5x94EREmgW4dRw4A5yISLcAD3QBRERBRKsAt2IDnIhItwC33VKNEU5EpFWA264HHuA6iIiCgVYBTkRE1RjgRESa0irArafSP/qf/SitMAW2GCKiANMrwO0eF5ZXBqwOIqJgoFWA24sI07Z0IiKv0CoF7W/IYzJzLAoRhTa9AtyuE4VjwYko1GkV4PZMDHAiCnH13lItGFSZzDiRU+wwjV0oRBTqtAjwV1Ydwz82n8TohLa2aWyAE1Go06ILZc+ZCwCAvKJy2zS2wIko1GkR4FZiNwzFzCY4EYU4rQLcHgOciEKdxgEe6AqIiAKr3gAXkcUiki0iB52mPygix0TkkIi87LsSHcd/W7EPnIhCnTst8CUAptlPEJGJAK4HMEQpNRDAQu+XVpN9jDPAiSjU1RvgSqnNAM47Tf4tgAVKqXJjnmwf1FZPXf5eIxFRcPG0D7wvgKtEZKeIbBKRUbXNKCL3ikiSiCTl5OR4uDrrsqof80xMIgp1ngZ4BIA2AMYA+DOAf4v9GD87SqlFSqlEpVRibGysh6uriaNQiCjUeRrg6QCWKYtdAMwA2nuvLNfsD2aa2QdORCHO0wD/CsA1ACAifQE0AZDrraLcwfwmolBX77VQRGQpgAkA2otIOoBnASwGsNgYWlgBYLby5fVdXXTOcBQKEYW6egNcKXVLLS/d5uVa6mXfy87rgRNRqNP2TEyOQiGiUKdvgLMLhYhCnFYBbj9SkQ1wIgp1WgW4PbbAiSjUaRvgPJGHiEKdVgFuP5qQAU5EoU6vALdLcPagEFGo0yLArblt3+hmHzgRhTotAtzKvgX+zNcHeT0UIgpp2gb4hZJKpOUVB64YIqIA0yrAnbm8fi0RUYjQOsCJiEKZFgHu+lYRjmdmEhGFGi0C3Mr57vSMbyIKZVoFOBERVdMqwJ17TDiIkIhCmWYB7pjgPJmHiEKZFgFu7fsOc2qB83ooRBTKtAhwqzC2wImIbDQLcMfnbIETUSjTKsCd+8DN5gAVQkQUBLQKcOcWOG9sTEShTLMAd2qBM8CJKITpHeA8iElEIUyLALfmtvOJPByFQkShrN4AF5HFIpItIgddvPaIiCgRae+b8mqsz+E5+8CJKJS50wJfAmCa80QR6Q5gCoAzXq6pVs4HMd9cm+KvVRMRBZ16A1wptRnAeRcvvQ7gUfjxkiTOfeA701yVRUQUGjzqAxeRnwM4q5RKdmPee0UkSUSScnJyPFmdjXMLnIgolDU4wEWkGYAnATzjzvxKqUVKqUSlVGJsbGxDV+e87ka9n4joUuJJC7wXgAQAySJyCkA3AHtEpJM3C3OFLXAiomoRDX2DUuoAgA7W50aIJyqlcr1Yl0vOd+QhIgpl7gwjXApgO4B+IpIuInf7viznGhx/EhGRGy1wpdQt9bwe77Vq6sEAJyKqpsWZmFY8b4eIqJpWAU5ERNUY4EREmmKAExFpSqsAd9UHnpZb7P9CiIiCgBYBbh3/rYzLrtw2Js722qurjwWkJiKiQNMiwJ39flIf2+PcovIAVkJEFDhaBri9yHDtN4GIyCPap192AVvgRBSatA3webMGAQCOZRUGuBIiosDQKsCto1AEgpE92gS2GCKiANMqwO2ZeV49EYU4LQLc1UWsmN9EFOq0CHBXGOBEFOq0CnD7zG7apLr0n86X+L8YIqIA0yrA7fXuEGN7/Lt/7glgJUREgaFtgNurNJkDXQIRkd9pFeC2YYS8Mw8RkV4BXhuTmUc0iSj0XBIBnpJdFOgSiIj87pIIcCKiUMQAJyLSlGYBXntft5n94EQUYrQIcDGGndR19uWXe8/6qRoiouBQb4CLyGIRyRaRg3bTXhGRoyKyX0S+FJHWvi3TqSYX0y6UVPizBCKigHOnBb4EwDSnaWsADFJKDQFwHMDjXq7LLRFhHBBORKGr3gBXSm0GcN5p2mqlVJXxdAeAbj6orV775/4sEKslIgoK3ugDvwvAd15YTr2cu8DFrjOFVyckolDTqAAXkScBVAH4Zx3z3CsiSSKSlJOT05jVuVh29eOTucVeXTYRUbDzOMBFZDaAawHcqlTt7V+l1CKlVKJSKjE2NtbT1VmXVetrS3edadSyiYh041GAi8g0AI8B+LlSyucX47Y2tM22i1mJ8dNxvuzCMl+XQkQUNNwZRrgUwHYA/UQkXUTuBvA2gBgAa0Rkn4j83cd1uq7NaUDh6BfXoai8qpa5iYguLRH1zaCUusXF5A98UEu9ahzEdDGKsKSiCi2i6t0sIiLtaXEmZm1cjQIP48XCiShEaBXgzgcxxUVYM8CJKFRoFeDOXEU145uIQoXeAe4irXk+DxGFCq0C3HZPTOO5qy6UZXvS/VcQEVEA6RXgbrSv56044odKiIgCT4sAtza0eb0TIqJqWgQ4ERHVpFWAu2qBPzS5j/8LISIKAloFuCtX9al5gaycwvIAVEJE5F9aBbirg5gje7SpMY3XQyGiUKBXgNuuRlj3fDtP5jHEieiSp0WAW/O6tlEoky/r4PB8zrIDuO+TJN8WRUQUYFoEeHiYpcwqs9nl622aNakx7ce0Cz6tiYgo0LQIcOvd50srXQe4KxUm9+clItKRFgEeHm4J8CMZBS5f5/k9RBSK9AhwXiKWiKgGLQLc2oVi5XwrNZ5iT0ShSIsADw+ruwXuPAqFiCgUXBIBPjyu5sk8RESXuksiwM3sQyGiEKRFgDv3gbvraKZl1EqVyYxPd5xGFYcWEtElRIsAt57IU5va2t/T3tiCskoT3libgqe+Oogl2055vTYiokCJCHQB7qivAd7WxZmYVrPe2YqjmYUAgPkrjyC7sBxPzLjMm+UREQWEFi3wGpwCvWmTcJxaMNPlrNbwBgCzAhZtPunLyoiI/KbeABeRxSKSLSIH7aa1FZE1IpJi/AyKYSBv3DQMt4/pEegyiIj8wp0W+BIA05ymzQGwTinVB8A647nPuDvGZNbwrujdoUW98y3afALzV/Lmx0Skt3r7wJVSm0Uk3mny9QAmGI8/ArARwGNerMtjyo0hhfNXHgUAXNY5BuFhYfj50C6+LouIyOs8PYjZUSmVAQBKqQwRqfVUSBG5F8C9ABAXF+fh6tzXkBHhD3+eDAAMcCLSks8PYiqlFimlEpVSibGxNe9f6d4y3J/X1bXBiYguRZ4GeJaIdAYA42e290pqHE9a08W8/RoRacjTAP8GwGzj8WwAX3unHNecb2Zc19Vlwzw4a/PcxdIGv4eIKNDcGUa4FMB2AP1EJF1E7gawAMAUEUkBMMV4HjSmD+rUoPmnvL4ZC1cd81E1RES+UW+AK6VuUUp1VkpFKqW6KaU+UErlKaUmKaX6GD/P+7LIhl6r6p3/HdHgdby9IRU/nS9p8PuIiAJFzzMx6+FJNwoAXP3KBi9XQkTkO5dkgHvKrICPt5/CxZIKZBWUBbocIqI6XbIB/uqNQz163zNfH8Kw59fg8vnrvFwREZF3aRng7nSQ/GJEV5/XQUQUSFoEuDunxzsTL9zJ/tXVHJlCRMFLiwAPlLfWpyJ+zgqUVZoCXQoRUQ0hEeBTBnRs1Pv7P/29lyohIvIeLQJcAWjdLLLB7xsd3xYAcFNid3RpFY2E9s0bXYvZrHjmJhEFBS0CHHDvwKWzByf1RniYYFRCW2x7fBKGx7X2eP33f7YHZrPC3zadwBUL1iMtt9jjZREReYMW98T04BgmAOCqPrE4MX+G7Xn/TjEAgKW/GYNb3tvRoGWt2J+B80UVMBvFZOaXeaVFT0TkKS0CHHAcVeLpCJN7xvXE6IR2GNbds5b49pN5tsfOF9giIvI3bbpQvCEsTDwOb2dvr09FeZUJ3ySf82iYIxEF3g8puVp3h2oR4E/OvAyb/jzBZ8uPDG94i37biTzM/eYQfr90LzYey/FBVUTka7d9sBMTF27EC8sPazlcWIsAj44MR0x0w0ehuGtc7/Y4+sI03DG2YXe0X7E/AwBwoaTCF2URkZ988EMalu46E+gyGkyLALdqEuGbcsNEEB0ZjuevH9Sg95lV9c+CskofVEZE/lJl0q8rVKsAbxoZDgCorDJ7dbnXD6++bsqnd1/u9vuKjFuxHUi/iCFzV+Pb5HM4klGAo5kFXq2PiHzvxZVHAl1Cg2kV4G/dMhyj49uiZdPGd6f8amQ3DOnWCqcWzHS4j+a4Pu3x/h2JDVrWR9tPAwA2HM3G9De3YNobWxpdHxFRfbQZRggA4/vGYnxfz+5s72xhHZebbdok3KNlLtt71tNyiIgaTKsWuL9UGZ3bV/Vp7/Ey4ues4PBCIs3oNhKFAe6C2Qjw8DDB7qcm49ohnT1azqc79TuqTRTK1h7JCnQJDcIAd8HaAo8IE7RrEYWRPdrYXhvUtaXby3n6q4MoKq9CSYXlYGdqdhHKq/T6hCcKJcXGwARdaNUH7i8ms2WUS5hxyv7ssfHo2DIaSacuoEVUOA6edX+UyaBnVwEA/vfyOHy28wyGdmsFAPj0nst9OradQlNBWSWiIsIQFeHZcZxQ99h/D+CmUXGBLsNtbIG70K+TpZU90+g6CQsTzBjcGc9cNwC/ndDbo2V+ZnSnJKfnIzk9H5uP5wIALhRX4IHP9mDN4SwUciw5NdKQuatx63s7A10G+Qlb4C4ktG+OlBenIzK85ueb/QiVjY9MwISFGz1ah4jlgMlb61OxfH8Glu/PwJBurRAVEYYP7xyNFlHcNeSZpNMXAl2C1pRSXrkloz8wJWrhKrytjr4wDZUmM2KiI7Hi9+Mw868/NHj5v/vnnhrT9qfnAwBe+PYwXpg1yGdnnhKR4712Y2OikFNYDgC4edEOfH7f2ECV1SCNSggReVhEDonIQRFZKiLR3iosmNlfm2Vgl1Zeu8Kh1edJP6HvU9/hj5/vw4Zj2S7nKas02c4EdZaaXYQ316a4PYxx2Z50jPvL+qAd9rg//SLi56zAWd4JibzIbPfn/sSM/rbHO9POB6Aaz3gc4CLSFcDvASQqpQYBCAdws7cK08mfftYXMdERWPvH8V5d7rK9Z3Hnhz86TFNKYe43h9D/6e8x6NlV+NvGEwCAKpMZb69PwfGsQkx+bRNeX3scBaVVqHBx2YG8onKH5498kYz0C6Uoq/TuJQq8xXqRoY21fJgRecJkJPj9E3vhhuHdHF6zjhwLdo39jh4BoKmIRABoBuBc40vSz1V9YnFg7lR0bOmbLyCvrDqKh/61Fw8u3YuEx1diybZTttf+8v1RAMCKAxlYuPo4fvb6Zttre85cQN+nvsO21FwopZCSVYj1R7Mwct5abE3Ntc1nbYn8O+knj2tMv1CC9zaf9Pj9dbH2R/r6C0JGfqnLDzy6NFnvrtXcON4U366Z7bVPjMtjBDuPA1wpdRbAQgBnAGQAyFdKrXaeT0TuFZEkEUnKybm0r5sdEx2JA3N/hsmXdfTqct/ZcAJf7TuHb5Ndfz7Gz1mB9Udrtk7vXGJpvc/+cBf+9EUypry+GXctSQIALNl2CoPnrnLollhz2HISw8mcIsTPWYGDZ/Ntr5VUVCEj3zJvXlF5jREzdy35ES+uPILM/DKXNdq3+p/+6iB6Pr6i3u22sh5Ocu7iqTKZ8c6GVJRW1D+2fsnWNHxk98Fn78dT5xE/ZwXGvrQec/67HwBwLLOwQWHe2DP4CsoqtTsLUHfWPyfrcOG3/3eE7bWXvrM0jMqrTLjipXVYezg4T/BpTBdKGwDXA0gA0AVAcxG5zXk+pdQipVSiUioxNtY71zEJZjHRkYgI8/8R7K/31f7lp9KksGyP43VaLMMWq3DlgvW2aT+k5mLJ1jTbh8F/dqfjhne3In7OCsxevAtjX1qP3afPY+S8tRg81/GzOr/UEui5ReXYffoCtqRUf1hvO5GLkfPWYurrmzHtjc34ZMdpmBVwPKsQf/jXXiiloJTCV3vPotJUMzT/szsdgGOfJQAs23MWr6w6hkf+k2z7gDCZFb5I+glVJjPKKk14f8tJPPDZHsz99jCe/eaQ8fswY9WhTNsHwiK7bw6rDmUiM78MU9/YjLnfHqr1d2qllELyTxfR/+nvscHpQ3Tt4Sz8fdMJh9/DX9eluFzOkLmrMeudrQ7T3t2Yaht+6omKKrNPhqZ+uDUN72/x/retcxfr/wZUWmHC62uON/ib0sWSCjz8+T6H40bWFrj1v2t0pOPY+fPFFcjML8O5/DI8v/xwg9bnL40ZhTIZQJpSKgcARGQZgCsAfOqNwnR2xxU98P2hTOx4fBJMSqGorApT39hc/xuDwNxvq/9Q7btqfjxlGZr2y79tt037ISUXXVpH484lPyKrwBKg175VPSInvl0z3D42Hi8Yf/zHsgod1mXt7vl63zn07dgCx7OKkJx+ET3aNsPsK+KRXViOl78/hnLjP6vZrgV+Oq8Y725MBWC5scaK/RmYMqAjxvdpj6e/PoTi8ipkFJThH5scg2b+yiOIiYrAq2uO4707EjGxX6xD8BZXmPDpDsvX5892nsH8GwYDAN5al4K03GK8cuNQhNt9QCc8vtL2eHNKDib274D0CyVoGhmOez62fNuZNawrdpzMw0Of7wMAXN03FmWVJlzes51DbUczC5GSVYhHvkjGp/dcjpe/PwYAmNg/Fo/+Zz/evHk42jZvAmfL9qTjqj6xiI2Jqv7dz6n+hjNv1iDcNqbum5WUV5lw6FwBRsS1wancYpy9WIrl+8/h11ckoFdsc0QYo7JWHcrEc8bfyKbjOZjUvwN+fWVCnct2R3mVCVcsWI9Zw7rgnqt6orTShLJKE9o1j0LLphHo1sbSvfHW+hS8u/EEYmOi0K9TDFYeyMCHW0/hwWt64+bRcejauqnDcksqqmBWwLsbT+DLvWfRv1MM7ru6FwDAZAtwy/5s4jTy7IllBzBnuuXgpsms8K9dZzChXwekZBfiqj7uN0bzSyux/UQepg3q5Nkvpw7i6cgDEbkcwGIAowCUAlgCIEkp9VZt70lMTFRJSUkerU93O0/m4a/rU7A11XJj5Psn9sI7G07U867Q9eqNQ7H+aDZWHMhwmP6LEV1RVmnCygOZdb7/zivjcaG4Al+5+GZy7ZDOWL4/A+Fhgr4dY3Ako/Yza394bCLG/WWD7fnqh8ejb8cYfLTtlK1Fb29Mz7bYcdK9UQxDurXCfeN74f7PqoeUThvYCd8fysS8WYPw1FcHHeb/89R+uH+i5USykooqPPnlQcwc3Bn3fJyEod1a4esHxjkEtyt/v20kIsMFf/oiGbeP6YHhca1t3WoAcGXvdra/UXthAtwyOg7/dPGN4Pi86bYhr+eLK3DmfAmaNwlHQvvmyC+tRHL6RVzTv7pb8ckvD2Bot9YY0KUljmYW4lcju+Efm07Yui1cmTKgIzrERKG4vMrlPrX6YHYiJtl1YQ6euwqFZdWt7rvHJeDpawcAAPJLKjH0+dV45toBuGtcAjLySzH2pfUOy5t/w2A88eWBGus5OX8GDpzNx/XGt6alvxmDzq2ibeeFHH5+KgY8YzkLe2CXljh0rgBbHp2I7m2b1ViWO0Rkt1KqxnWuPQ5wY6HPAbgJQBWAvQDuUUqV1zZ/KAc4YPm6fcO72/DsdQMwPK4NCsoqMcToipg9tgfySyvr/OOkwPv7bSNxPKsQr6057vd1/2lKXzw4qU+9Ie1vXVs3xRs3D0N0RDgeWLoHp/NKbK/1im2OEznFmNS/A0oqTNh+suaHQ2KPNl49+Whot1ZY9rsr8beNqVi42vV+eva6AZgxuDMun78Oc68bgF9fmYDSChMue+Z7r9Xh7OlrB+DucZ59W/FJgDdUqAe4K//zj+3YlXYepxbMBGC5mM7TXx3ktcWJGuGyzi3r/GZlz/6bTVF5le36Rd72/PUDccfYeI/eW1uA81S/AFv6mzE4Nm+a7XnzqAi8dtMwfPF/Y/HtA+Ns0y/rbLk+i7X/9ev7r8T6P13tcpm/m9DLhxUTBT93wxsA3lxbfWDZl5ewiPbBBcZ4Kn2AhYcJwsNq7thR8W0BAJv/PBEiwMLVx3AkowALbxxS46SDMKkeofHf316B4d1b492N1f3rr/xqCKIjw3HgbD4qTWZ8uPVUjfVZDyIShZpr+nfwy3omD/Du8GKAAR704oyTC6w9XQLHIYrWrhdrv6j12uWLf51oOzh1Y2J3AMB1xr0/n71uIAAgM78M20/m4uHPk9GldVO8e+tITH5tk1t1fXzXaNyxeJenm0UUNH4zvqdf1uNqBFFjsQtFE307tgAAdGrl+mzPt24Zjr/8crDtuf1R/9p0ahWNWcO6Yt6sQXjtf4ahd4cWOLVgJh6e3Bfv35GInU9Msn1AWL1641C0aRaJ0Qlt8cNjE7Ho9pFIfXE6/jy1n8N8x+ZNwx+n9EVEmGBUvOVD5f6JvTCxn+Pwq8em9Ycr62rpHppey1CsVnY3ur718jh8+OtRLufr3ykGoxPaunwNsHRpbXl0Yq2vu/KP20fi50O7YHR87csNhKg6LoZ2y+juLqc7D6VrjFdvHIrLXfyuH53Wz8Xc3mPtbnSXc7C+/MshWP7guFrmrja+byxW/L7++XyJBzE1YTIr7Dlzwda14o4C4ySOlo28ccSaw1m4UFyBYXGt0bdjjMt5lmxNcxhDbh/8ZrNCUUWVrY4zeSXYdiIXJRUm3DUuAeeLK7DzZB4OnStAXnEFlu46g1MLZuJkThHyiivw3YFMLN6aBsAyfGvMS+uQXeg42Om+q3vaxnwffG4qWkRF4O+bTmD36QtYczgLMwd3xju3Vp9pt+NkHm5etKPGdljr3pV2Hh1bRuHFFUew+nAW3r11BIZ2b+1w4hNgGYGxdc41tufOI0TG9mzncuQFYBmVsGxPOg6dc91f+8DE3jiaWYCxvdpjybY03DwqDq+sOoaxPduhbYsmWLHfcYhlu+ZN0K1tM/xuQi/07xSDuLbNcLGkEnnF5agyK0x7Y4tt3n/fNxbzVx7Bvp8uIjJcUGlSuHlUdyz45ZBaR7n0jG2OkznFDtM6xEQhu7Acw+NaY++Ziw6vHZ83HZuP5+Cej5Pwh0l98MmO03h4ch/cNqaHw/h5AGjTLBJr/3g11h3JxqPG2bCuOH/jdHboualoHhWB+DkrcO2QzrhjbDy+TT6HJhFh+HBrGpo3iUCh3ck8L8wahNtrGSN/2/s78UNqLl76xWA89dVBmMwK3z90le33eGrBTFRUmdH3qe8AAElPTUb7FlHILSqHyawQHRmOoc+txqj4Nvj0nssbdZMNjkIhn7L0radhf3o+Jl/WEbOGd/Xq8q33KQ0LE/z87R9sl961Sn1xOo5mFqJ3hxY1zqjLL61EsybhNS4RfCSjAN3bNsOt7+/EHyb1RudWTWu03h7+fB++3HsWS+4chQn9OtiC45cjuuG56wfWOOjlPJZ465xrcOWC9XjjpmG2E3le+sVgFJZV4t7xloPN85Yfxvs/WD6gWjeLxMWSSux7ZgpaN6v5lTu/pBItoiMQHiYoLq/CQGPExP9d3ct20kld7v9sD1bsz8CuJyahXYsomJWq8XvZeTIPW1JyUVhWie5tm2HeiiMALB+My5PP4aZR3W0BnPridPx0oRQJ7ZtjxAtrcL64Au/eOgIzBtd9H9m03GJ8dzDDdrKS8zc9oPp3/9Fdo5GVX4ZOraIxvq/lG5x1P3RuFY1P7h6Nbm2aobTChDZGa7q8yoSIsDCHk66srO9Ne2lGndf9zswvw6c7TuOPU/oizG451vdba75YUoGdaecxdWDNb4fWfG3s9cVrC3Dbacz++Ddy5EhF1FiZ+aVq6c7TqqS8SuUUlqm8onKfreticYV6e32KMpnMSimldqXlqTN5xXW+p8djy1WPx5arA+kXHaaXVlSpjceyXb6nrLJKzflvssrKL21QfSlZhSrp1Hm35zebzarK2BZ3ZeaX1tjmU7lFKqvAsdZjmQXq2r9uUfmlFW4ve8PRLLXleI7L1y6WVKj3Np9QZnPNehdtOqH2/3TRxbvqZ90/nnpr3fFa96OvwHKSZI1MZQucyMvWHM5C51bRGNS1VaBLIRcOncvHrrTzuNMLlwDwl9pa4ByFQuRlU3wwXPPDlbsAAARUSURBVIy8Z2CXVhjY5dL4cOUoFCIiTTHAiYg0xQAnItIUA5yISFMMcCIiTTHAiYg0xQAnItIUA5yISFN+PRNTRHIAnPbw7e0B5HqxnEDitgSfS2U7AG5LsGrMtvRQStW4k7JfA7wxRCTJ1amkOuK2BJ9LZTsAbkuw8sW2sAuFiEhTDHAiIk3pFOCLAl2AF3Fbgs+lsh0AtyVYeX1btOkDJyIiRzq1wImIyA4DnIhIU1oEuIhME5FjIpIqInMCXU99ROSUiBwQkX0ikmRMaysia0QkxfjZxm7+x41tOyYiUwNXOSAii0UkW0QO2k1rcO0iMtL4HaSKyF+lsTcF9N62zBWRs8a+2SciM4J9W0Sku4hsEJEjInJIRP5gTNduv9SxLTrul2gR2SUiyca2PGdM999+cXWftWD6ByAcwAkAPQE0AZAMYECg66qn5lMA2jtNexnAHOPxHAB/MR4PMLYpCkCCsa3hAax9PIARAA42pnYAuwCMBSAAvgMwPUi2ZS6AR1zMG7TbAqAzgBHG4xgAx416tdsvdWyLjvtFALQwHkcC2AlgjD/3iw4t8NEAUpVSJ5VSFQD+BeD6ANfkiesBfGQ8/gjALLvp/1JKlSul0gCkwrLNAaGU2gzgvNPkBtUuIp0BtFRKbVeWv86P7d7jN7VsS22CdluUUhlKqT3G40IARwB0hYb7pY5tqU0wb4tSShUZTyONfwp+3C86BHhXAD/ZPU9H3Ts8GCgAq0Vkt4jca0zrqJTKACx/xAA6GNN12L6G1t7VeOw8PVg8ICL7jS4W69dbLbZFROIBDIeltaf1fnHaFkDD/SIi4SKyD0A2gDVKKb/uFx0C3FVfULCPfbxSKTUCwHQA94vI+Drm1XH7rGqrPZi36W8AegEYBiADwKvG9KDfFhFpAeC/AB5SShXUNauLacG+LVruF6WUSSk1DEA3WFrTg+qY3evbokOApwPobve8G4BzAarFLUqpc8bPbABfwtIlkmV8VYLxM9uYXYfta2jt6cZj5+kBp5TKMv7TmQG8h+ruqqDeFhGJhCXw/qmUWmZM1nK/uNoWXfeLlVLqIoCNAKbBj/tFhwD/EUAfEUkQkSYAbgbwTYBrqpWINBeRGOtjAD8DcBCWmmcbs80G8LXx+BsAN4tIlIgkAOgDywGNYNKg2o2vjYUiMsY4mn6H3XsCyvofy3ADLPsGCOJtMdb7AYAjSqnX7F7Sbr/Uti2a7pdYEWltPG4KYDKAo/DnfvHnUdtGHO2dAcvR6hMAngx0PfXU2hOWI83JAA5Z6wXQDsA6ACnGz7Z273nS2LZjCMBoDaf6l8LyFbYSlpbB3Z7UDiARlv+EJwC8DeOs3yDYlk8AHACw3/gP1TnYtwXAOFi+Uu8HsM/4N0PH/VLHtui4X4YA2GvUfBDAM8Z0v+0XnkpPRKQpHbpQiIjIBQY4EZGmGOBERJpigBMRaYoBTkSkKQY4EZGmGOBERJr6f0oDNgxOgcweAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(train_losses)), np.array(train_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b1,b2,b3,b4 = next(iter(train_dataloader))\n",
    "b1 = b1.cuda()\n",
    "b2 = b2.cuda()\n",
    "b3 = b3.cuda()\n",
    "b4 = b4.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b1.shape, b2.shape, b3.shape, b4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z1 = torch.nn.Parameter(torch.ones_like(b1).float()).long()\n",
    "z2 = torch.ones_like(b2)\n",
    "\n",
    "z1_dash = z1 + 5\n",
    "z2_dash = z2 + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t = summary_model(b1, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t.logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t_dash = merge_model(b1, b2, b3,b4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t_dash[0].logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss = mse_loss(t_dash[1], t_dash[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(torch.autograd.grad(loss,merge_model.summary_model.parameters(), retain_graph=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

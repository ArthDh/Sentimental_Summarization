{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "from utils.file_utils import *\n",
    "from datasets import list_datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from IPython import get_ipython\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from models.MergeModel import MergeModel\n",
    "from models.ClassifierModel import ClassifierModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "get_ipython().run_line_magic('autoreload', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50265"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 11,490\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8768</th>\n",
       "      <td>A surrender order issued by Hitler's successor...</td>\n",
       "      <td>Typed dispatch sent by German president Karl D...</td>\n",
       "      <td>bcbdb86d4eba1a7fac7e262cfb661f0113b755b5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>The world’s third largest cruise liner today s...</td>\n",
       "      <td>Two large cruise ships - Anthem of the Seas an...</td>\n",
       "      <td>795ec7ced1ec15f19b38e88aea63079cb996dc51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6901</th>\n",
       "      <td>Big-hearted Ipswich Town left back Tyrone Ming...</td>\n",
       "      <td>Left back posted screenshot of text message co...</td>\n",
       "      <td>8e2a91eb8fecd055aac9ff9f9ecead6e09287ebd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>As Prime Minister David Cameron puts it, on St...</td>\n",
       "      <td>Fish and chips has believed to be partly Portu...</td>\n",
       "      <td>1dd5816322e998cb7b4745363767ccee5ffd639d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>Spain's 2-0 defeat by Holland on Tuesday broug...</td>\n",
       "      <td>Holland beat Spain 2-0 at the Amsterdam Arena ...</td>\n",
       "      <td>7c9201a07ffd4647e3c37af77b69571e0fad1c45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Sometimes, putting up a billboard just isn't q...</td>\n",
       "      <td>Two Russian companies have started offering un...</td>\n",
       "      <td>da645b6de7f2f0b4d96b7b5dab962540d78d6aad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>A mother has released images of her teenage so...</td>\n",
       "      <td>The teenager suffered a broken jaw in 2 places...</td>\n",
       "      <td>2c39cb95345ead8ea9ff4f9e2229faddfebc8db4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>(CNN)The killing of an employee at Wayne Commu...</td>\n",
       "      <td>Relatives of Wayne Community College shooting ...</td>\n",
       "      <td>c0340e53445e1d38aaf9a2681c2ae2e950a98860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>A woman has received the shocking news that th...</td>\n",
       "      <td>Sarah appeared on Monday's Jeremy Kyle Show to...</td>\n",
       "      <td>0312bea2586ef3a65a1b9a3d25328d1b417e2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9150</th>\n",
       "      <td>EU leaders have agreed a package of measures t...</td>\n",
       "      <td>Funding increased to £7m a month for EU's bord...</td>\n",
       "      <td>c61946875505531b55fb6d23decb7f7186f66a40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                article  \\\n",
       "8768  A surrender order issued by Hitler's successor...   \n",
       "6087  The world’s third largest cruise liner today s...   \n",
       "6901  Big-hearted Ipswich Town left back Tyrone Ming...   \n",
       "2339  As Prime Minister David Cameron puts it, on St...   \n",
       "6214  Spain's 2-0 defeat by Holland on Tuesday broug...   \n",
       "9996  Sometimes, putting up a billboard just isn't q...   \n",
       "2891  A mother has released images of her teenage so...   \n",
       "802   (CNN)The killing of an employee at Wayne Commu...   \n",
       "1212  A woman has received the shocking news that th...   \n",
       "9150  EU leaders have agreed a package of measures t...   \n",
       "\n",
       "                                             highlights  \\\n",
       "8768  Typed dispatch sent by German president Karl D...   \n",
       "6087  Two large cruise ships - Anthem of the Seas an...   \n",
       "6901  Left back posted screenshot of text message co...   \n",
       "2339  Fish and chips has believed to be partly Portu...   \n",
       "6214  Holland beat Spain 2-0 at the Amsterdam Arena ...   \n",
       "9996  Two Russian companies have started offering un...   \n",
       "2891  The teenager suffered a broken jaw in 2 places...   \n",
       "802   Relatives of Wayne Community College shooting ...   \n",
       "1212  Sarah appeared on Monday's Jeremy Kyle Show to...   \n",
       "9150  Funding increased to £7m a month for EU's bord...   \n",
       "\n",
       "                                            id  \n",
       "8768  bcbdb86d4eba1a7fac7e262cfb661f0113b755b5  \n",
       "6087  795ec7ced1ec15f19b38e88aea63079cb996dc51  \n",
       "6901  8e2a91eb8fecd055aac9ff9f9ecead6e09287ebd  \n",
       "2339  1dd5816322e998cb7b4745363767ccee5ffd639d  \n",
       "6214  7c9201a07ffd4647e3c37af77b69571e0fad1c45  \n",
       "9996  da645b6de7f2f0b4d96b7b5dab962540d78d6aad  \n",
       "2891  2c39cb95345ead8ea9ff4f9e2229faddfebc8db4  \n",
       "802   c0340e53445e1d38aaf9a2681c2ae2e950a98860  \n",
       "1212  0312bea2586ef3a65a1b9a3d25328d1b417e2871  \n",
       "9150  c61946875505531b55fb6d23decb7f7186f66a40  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence = df.article.values\n",
    "train_target = df.highlights.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_points = 10000\n",
    "train_sentence = list(train_sentence[:num_data_points])\n",
    "train_target = list(train_target[:num_data_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_encoding = tokenizer(train_sentence, return_tensors='pt', padding=True, truncation = True, max_length=500)\n",
    "summary_encoding = tokenizer(train_target, return_tensors='pt', padding=True,truncation = True, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_input_ids = article_encoding['input_ids']\n",
    "article_attention_mask = article_encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_input_ids = summary_encoding['input_ids']\n",
    "summary_attention_mask = summary_encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 500]) torch.Size([10000, 500])\n"
     ]
    }
   ],
   "source": [
    "print(article_input_ids.shape, article_attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 100]) torch.Size([10000, 100])\n"
     ]
    }
   ],
   "source": [
    "print(summary_input_ids.shape, summary_attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_data = TensorDataset(article_input_ids, article_attention_mask,\\\n",
    "                           summary_input_ids, summary_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(lm_logits, labels):\n",
    "    loss_fct = CrossEntropyLoss(ignore_index = tokenizer.pad_token_id)\n",
    "    loss = loss_fct(lm_logits.view(-1, vocab_size), labels.view(-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'ClassifierModel.ClassifierModel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "sent_model = torch.load('experiment/classifier/classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierModel(\n",
       "  (embedding): Embedding_(\n",
       "    (embedding): Embedding(50265, 64)\n",
       "  )\n",
       "  (lstm): LSTM(64, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (fc1): Linear(in_features=512, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_model = summary_model.cuda()\n",
    "senti_model = sent_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_dim = 64\n",
    "# out_dim = 2\n",
    "# n_layers = 4\n",
    "# hidden_size = 512\n",
    "merge_model = MergeModel(summary_model, senti_model)\n",
    "model_name = 'BART_classifier'\n",
    "model_dir = './experiment'\n",
    "model_path = os.path.join(model_dir,model_name)\n",
    "epochs  = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "#     'embedding_dim': embedding_dim,\n",
    "#     'out_dim': out_dim,\n",
    "#     'n_layers': n_layers,\n",
    "#     'hidden_size': hidden_size,\n",
    "    'model_name': model_name,\n",
    "    'epochs':epochs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False, model_dir='./experiment',optimizer='ADAM',config = None):\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    min_val_loss = np.inf\n",
    "    \n",
    "    model_name = config['model_name']\n",
    "    print(f\"Start training for Model {model_name}...\\n\")\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(os.path.join(model_dir,model_name)):\n",
    "        os.mkdir(os.path.join(model_dir,model_name))\n",
    "    model_path = os.path.join(model_dir,model_name)\n",
    "    write_to_file_in_dir(model_path, 'config.json', config)\n",
    "    \n",
    "    train_log =  'train_log.txt'\n",
    "    write_string_train = f\"Epoch, Train_Loss, Train_Acc\"\n",
    "    log_to_file_in_dir(model_path, train_log, write_string_train)\n",
    "\n",
    "    if evaluation:\n",
    "        val_log = 'val_log.txt'\n",
    "        write_string_val = f\"Epoch, Val_Loss, Val_Acc\"\n",
    "        log_to_file_in_dir(model_path, val_log, write_string_val)\n",
    "    \n",
    "    if optimizer == 'ADAM':\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "    else:    \n",
    "        optimizer = torch.optim.SGD(model.parameters(),1e-3,momentum=0.9,weight_decay=0.01)\n",
    "    \n",
    "    for epoch_i in range(epochs):\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "        model.train()\n",
    "        \n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            model.train()\n",
    "            batch_counts +=1\n",
    "            \n",
    "            batch[0] = batch[0].cuda()\n",
    "            batch[1] = batch[1].cuda()\n",
    "            batch[2] = batch[2].cuda()\n",
    "            batch[3] = batch[3].cuda()\n",
    "            \n",
    "            model.zero_grad()\n",
    "            \n",
    "            summary_out,*sentiments = merge_model(batch[0],batch[1], batch[2], batch[3])\n",
    "        \n",
    "            loss1 = loss_fn(summary_out.logits, batch[2])\n",
    "            loss2 = mse_loss(sentiments[0], sentiments[1])\n",
    "\n",
    "            loss = loss1+loss2\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            write_string_train = f\"{epoch_i}, {loss.item()}\"\n",
    "            log_to_file_in_dir(model_path, train_log, write_string_train)\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if (step % 100 == 0 and step != 0):\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "                print(\"-\"*70)\n",
    "\n",
    "        if ((epoch_i %20 ==0) and (epoch_i != 0)) or (epoch_i==epochs-1):\n",
    "            if evaluation == True:\n",
    "                val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "                val_losses.append(val_loss)\n",
    "                val_accs.append(val_accuracy)\n",
    "                \n",
    "                write_string_val = f\"{epoch_i}, {val_loss}, {val_accuracy}\"\n",
    "                log_to_file_in_dir(model_path, val_log, write_string_val)\n",
    "                \n",
    "                time_elapsed = time.time() - t0_epoch\n",
    "                \n",
    "                if val_loss < min_val_loss:\n",
    "                    min_val_loss = val_loss\n",
    "                    \n",
    "                    torch.save(model, os.path.join(model_path, f'{model_name}.pt'))\n",
    "                    \n",
    "                print(f\"{epoch_i + 1:^7} | {'-':^7} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "        \n",
    "    torch.save(model, os.path.join(model_path,f'{model_name}_final.pt'))\n",
    "        \n",
    "    return  train_losses, train_accs, val_losses,val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for Model BART_classifier...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   100   |  12.846584   |     -      |     -     |   50.12  \n",
      "----------------------------------------------------------------------\n",
      "   1    |   200   |   9.330114   |     -      |     -     |   49.89  \n",
      "----------------------------------------------------------------------\n",
      "   1    |   300   |   8.523876   |     -      |     -     |   49.99  \n",
      "----------------------------------------------------------------------\n",
      "   1    |   400   |   8.219645   |     -      |     -     |   50.13  \n",
      "----------------------------------------------------------------------\n",
      "   1    |   500   |   8.053046   |     -      |     -     |   50.42  \n",
      "----------------------------------------------------------------------\n",
      "   1    |   600   |   7.934429   |     -      |     -     |   50.29  \n",
      "----------------------------------------------------------------------\n",
      "   1    |   700   |   7.865319   |     -      |     -     |   50.55  \n",
      "----------------------------------------------------------------------\n",
      "   1    |   800   |   7.838752   |     -      |     -     |   50.61  \n",
      "----------------------------------------------------------------------\n",
      "   1    |   900   |   7.771807   |     -      |     -     |   50.63  \n",
      "----------------------------------------------------------------------\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   100   |   7.706820   |     -      |     -     |   50.91  \n",
      "----------------------------------------------------------------------\n",
      "   2    |   200   |   7.689942   |     -      |     -     |   50.77  \n",
      "----------------------------------------------------------------------\n",
      "   2    |   300   |   7.675963   |     -      |     -     |   50.51  \n",
      "----------------------------------------------------------------------\n",
      "   2    |   400   |   7.697523   |     -      |     -     |   50.72  \n",
      "----------------------------------------------------------------------\n",
      "   2    |   500   |   7.660037   |     -      |     -     |   51.28  \n",
      "----------------------------------------------------------------------\n",
      "   2    |   600   |   7.667022   |     -      |     -     |   50.49  \n",
      "----------------------------------------------------------------------\n",
      "   2    |   700   |   7.645872   |     -      |     -     |   50.58  \n",
      "----------------------------------------------------------------------\n",
      "   2    |   800   |   7.656322   |     -      |     -     |   51.18  \n",
      "----------------------------------------------------------------------\n",
      "   2    |   900   |   7.627994   |     -      |     -     |   50.38  \n",
      "----------------------------------------------------------------------\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   3    |   100   |   7.605158   |     -      |     -     |   51.05  \n",
      "----------------------------------------------------------------------\n",
      "   3    |   200   |   7.575696   |     -      |     -     |   50.94  \n",
      "----------------------------------------------------------------------\n",
      "   3    |   300   |   9.619936   |     -      |     -     |   50.51  \n",
      "----------------------------------------------------------------------\n",
      "   3    |   400   |   8.577678   |     -      |     -     |   50.49  \n",
      "----------------------------------------------------------------------\n",
      "   3    |   500   |   8.319487   |     -      |     -     |   50.52  \n",
      "----------------------------------------------------------------------\n",
      "   3    |   600   |   8.131080   |     -      |     -     |   50.48  \n",
      "----------------------------------------------------------------------\n",
      "   3    |   700   |   7.942659   |     -      |     -     |   50.42  \n",
      "----------------------------------------------------------------------\n",
      "   3    |   800   |   7.772335   |     -      |     -     |   50.74  \n",
      "----------------------------------------------------------------------\n",
      "   3    |   900   |   7.696350   |     -      |     -     |   50.69  \n",
      "----------------------------------------------------------------------\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   4    |   100   |   7.643537   |     -      |     -     |   51.27  \n",
      "----------------------------------------------------------------------\n",
      "   4    |   200   |   7.646576   |     -      |     -     |   50.71  \n",
      "----------------------------------------------------------------------\n",
      "   4    |   300   |   7.617484   |     -      |     -     |   50.72  \n",
      "----------------------------------------------------------------------\n",
      "   4    |   400   |   7.612858   |     -      |     -     |   50.43  \n",
      "----------------------------------------------------------------------\n",
      "   4    |   500   |   7.592558   |     -      |     -     |   50.47  \n",
      "----------------------------------------------------------------------\n",
      "   4    |   600   |   7.603532   |     -      |     -     |   50.48  \n",
      "----------------------------------------------------------------------\n",
      "   4    |   700   |   7.591156   |     -      |     -     |   50.43  \n",
      "----------------------------------------------------------------------\n",
      "   4    |   800   |   7.594651   |     -      |     -     |   50.46  \n",
      "----------------------------------------------------------------------\n",
      "   4    |   900   |   7.583461   |     -      |     -     |   50.59  \n",
      "----------------------------------------------------------------------\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   5    |   100   |   7.540297   |     -      |     -     |   51.16  \n",
      "----------------------------------------------------------------------\n",
      "   5    |   200   |   7.549271   |     -      |     -     |   50.64  \n",
      "----------------------------------------------------------------------\n",
      "   5    |   300   |   7.565000   |     -      |     -     |   50.86  \n",
      "----------------------------------------------------------------------\n",
      "   5    |   400   |   7.559536   |     -      |     -     |   50.72  \n",
      "----------------------------------------------------------------------\n",
      "   5    |   500   |   7.569402   |     -      |     -     |   50.78  \n",
      "----------------------------------------------------------------------\n",
      "   5    |   600   |   7.549438   |     -      |     -     |   50.75  \n",
      "----------------------------------------------------------------------\n",
      "   5    |   700   |   7.569551   |     -      |     -     |   50.81  \n",
      "----------------------------------------------------------------------\n",
      "   5    |   800   |   7.575276   |     -      |     -     |   50.63  \n",
      "----------------------------------------------------------------------\n",
      "   5    |   900   |   7.557424   |     -      |     -     |   50.64  \n",
      "----------------------------------------------------------------------\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   6    |   100   |   7.526545   |     -      |     -     |   51.31  \n",
      "----------------------------------------------------------------------\n",
      "   6    |   200   |   7.527972   |     -      |     -     |   50.48  \n",
      "----------------------------------------------------------------------\n",
      "   6    |   300   |   7.562263   |     -      |     -     |   50.75  \n",
      "----------------------------------------------------------------------\n",
      "   6    |   400   |   7.546673   |     -      |     -     |   50.75  \n",
      "----------------------------------------------------------------------\n",
      "   6    |   500   |   7.549926   |     -      |     -     |   50.73  \n",
      "----------------------------------------------------------------------\n",
      "   6    |   600   |   7.548823   |     -      |     -     |   50.66  \n",
      "----------------------------------------------------------------------\n",
      "   6    |   700   |   7.544580   |     -      |     -     |   50.54  \n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "stats = train(merge_model, train_dataloader, val_dataloader=None, epochs=epochs, evaluation=False,  config=config, optimizer='ADAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_accs, val_losses,val_accs = stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(train_losses)), np.array(train_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b1,b2,b3,b4 = next(iter(train_dataloader))\n",
    "b1 = b1.cuda()\n",
    "b2 = b2.cuda()\n",
    "b3 = b3.cuda()\n",
    "b4 = b4.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b1.shape, b2.shape, b3.shape, b4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z1 = torch.nn.Parameter(torch.ones_like(b1).float()).long()\n",
    "z2 = torch.ones_like(b2)\n",
    "\n",
    "z1_dash = z1 + 5\n",
    "z2_dash = z2 + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t = summary_model(b1, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t.logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t_dash = merge_model(b1, b2, b3,b4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t_dash[0].logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss = mse_loss(t_dash[1], t_dash[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(torch.autograd.grad(loss,merge_model.summary_model.parameters(), retain_graph=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import list_datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from IPython import get_ipython\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from models.MergeModel import MergeModel\n",
    "\n",
    "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "get_ipython().run_line_magic('autoreload', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50265"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 11,490\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>St. Louis Blues forward Ryan Reaves proved on ...</td>\n",
       "      <td>St. Louis Blues forward Ryan Reaves was checke...</td>\n",
       "      <td>0b1072939b9c0af0cfc29bcf92a1334630fb6325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>A guard at the U.S. Census Bureau headquarters...</td>\n",
       "      <td>A guard was shot and critically injured outsid...</td>\n",
       "      <td>281d340a0b9ba6fa2f5526ecd59db7cdcc1de4cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4661</th>\n",
       "      <td>In the dock: Victorino Chua, 49, has given evi...</td>\n",
       "      <td>Victorino Chua, 49, denies murdering patients ...</td>\n",
       "      <td>5681a060c743561b9718ac6d2b54ee0104e03fb0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6164</th>\n",
       "      <td>The Philadelphia Office of Transportation aims...</td>\n",
       "      <td>Road safety video stars walk streets in bizarr...</td>\n",
       "      <td>7b3060da24c633f153916892a0feb99135130c31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>A woman in China showed her strength by using ...</td>\n",
       "      <td>Woman performed stunt at a birthday party in S...</td>\n",
       "      <td>1fb282d29c002a41e08640a71c6c02bc54e65ba8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>Bitten: Austin Hatfield, 18, found the venomou...</td>\n",
       "      <td>Austin Hatfield of Wimauma was keeping the pot...</td>\n",
       "      <td>5d20cbef6b0db055b0938f5dc7535d8dbe2324c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9691</th>\n",
       "      <td>Baby Malakai has been alive for seven months a...</td>\n",
       "      <td>Baby boy Malakai suffers rare medical conditio...</td>\n",
       "      <td>d2c86883150136b6affe3a12aa6bcb7d2388591a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>A young mother diagnosed with dementia at only...</td>\n",
       "      <td>Kelly Watson began having problems with coordi...</td>\n",
       "      <td>1aa2504255a25e7497c3ba735665211fe22142b0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>Forget the must-have wine cellar, hot-tub or £...</td>\n",
       "      <td>Sir Philip Green and Benedict Cumberbatch also...</td>\n",
       "      <td>564ec07adee8078b31a5a6479e1bb16297022a3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6671</th>\n",
       "      <td>A 10-year-old boy who beat a younger child to ...</td>\n",
       "      <td>Lee Allan Bonneau, 6, was attacked by a 10-yea...</td>\n",
       "      <td>88ab1b6e345f7e16003f87ea53ffcbb746f33e21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                article  \\\n",
       "1568  St. Louis Blues forward Ryan Reaves proved on ...   \n",
       "2720  A guard at the U.S. Census Bureau headquarters...   \n",
       "4661  In the dock: Victorino Chua, 49, has given evi...   \n",
       "6164  The Philadelphia Office of Transportation aims...   \n",
       "2400  A woman in China showed her strength by using ...   \n",
       "4970  Bitten: Austin Hatfield, 18, found the venomou...   \n",
       "9691  Baby Malakai has been alive for seven months a...   \n",
       "2204  A young mother diagnosed with dementia at only...   \n",
       "4648  Forget the must-have wine cellar, hot-tub or £...   \n",
       "6671  A 10-year-old boy who beat a younger child to ...   \n",
       "\n",
       "                                             highlights  \\\n",
       "1568  St. Louis Blues forward Ryan Reaves was checke...   \n",
       "2720  A guard was shot and critically injured outsid...   \n",
       "4661  Victorino Chua, 49, denies murdering patients ...   \n",
       "6164  Road safety video stars walk streets in bizarr...   \n",
       "2400  Woman performed stunt at a birthday party in S...   \n",
       "4970  Austin Hatfield of Wimauma was keeping the pot...   \n",
       "9691  Baby boy Malakai suffers rare medical conditio...   \n",
       "2204  Kelly Watson began having problems with coordi...   \n",
       "4648  Sir Philip Green and Benedict Cumberbatch also...   \n",
       "6671  Lee Allan Bonneau, 6, was attacked by a 10-yea...   \n",
       "\n",
       "                                            id  \n",
       "1568  0b1072939b9c0af0cfc29bcf92a1334630fb6325  \n",
       "2720  281d340a0b9ba6fa2f5526ecd59db7cdcc1de4cc  \n",
       "4661  5681a060c743561b9718ac6d2b54ee0104e03fb0  \n",
       "6164  7b3060da24c633f153916892a0feb99135130c31  \n",
       "2400  1fb282d29c002a41e08640a71c6c02bc54e65ba8  \n",
       "4970  5d20cbef6b0db055b0938f5dc7535d8dbe2324c4  \n",
       "9691  d2c86883150136b6affe3a12aa6bcb7d2388591a  \n",
       "2204  1aa2504255a25e7497c3ba735665211fe22142b0  \n",
       "4648  564ec07adee8078b31a5a6479e1bb16297022a3d  \n",
       "6671  88ab1b6e345f7e16003f87ea53ffcbb746f33e21  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence = df.article.values\n",
    "train_target = df.highlights.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_points = 10\n",
    "train_sentence = list(train_sentence[:num_data_points])\n",
    "train_target = list(train_target[:num_data_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_encoding = tokenizer(train_sentence, return_tensors='pt', padding=True, truncation = True)\n",
    "summary_encoding = tokenizer(train_target, return_tensors='pt', padding=True, truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_input_ids = article_encoding['input_ids']\n",
    "article_attention_mask = article_encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_input_ids = summary_encoding['input_ids']\n",
    "summary_attention_mask = summary_encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1024]) torch.Size([10, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(article_input_ids.shape, article_attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 57]) torch.Size([10, 57])\n"
     ]
    }
   ],
   "source": [
    "print(summary_input_ids.shape, summary_attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_data = TensorDataset(article_input_ids, article_attention_mask,\\\n",
    "                           summary_input_ids, summary_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(lm_logits, labels):\n",
    "    loss_fct = CrossEntropyLoss(ignore_index = tokenizer.pad_token_id)\n",
    "    loss = loss_fct(lm_logits.view(-1, vocab_size), labels.view(-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/bart-base were not used when initializing BartForSequenceClassification: ['final_logits_bias']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.weight', 'classification_head.dense.bias', 'classification_head.out_proj.weight', 'classification_head.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "senti_model = BartForSequenceClassification.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_model = summary_model.cuda()\n",
    "senti_model = senti_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_model = MergeModel(summary_model, senti_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(merge_model.parameters(),1e-3,momentum=0.9,weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:04<36:15,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 78.049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/500 [00:45<33:26,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 62.404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 21/500 [01:25<31:59,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 47.068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 31/500 [02:05<31:22,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Loss: 42.038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 41/500 [02:45<30:26,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Loss: 39.869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 51/500 [03:25<30:10,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Loss: 37.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 53/500 [03:33<30:01,  4.03s/it]"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "\n",
    "for eps in tqdm(range(epochs)):\n",
    "#     print('Epoch: ', eps)\n",
    "    epoch_loss = 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        batch[0] = batch[0].cuda()\n",
    "        batch[1] = batch[1].cuda()\n",
    "        batch[2] = batch[2].cuda()\n",
    "        batch[3] = batch[3].cuda()\n",
    "        \n",
    "        summary_model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        summary_out,*sentiments = merge_model(batch[0],batch[1], batch[2], batch[3])\n",
    "        \n",
    "        loss1 = loss_fn(summary_out.logits, batch[2])\n",
    "        loss2 = mse_loss(sentiments[0].logits, sentiments[1].logits)\n",
    "        \n",
    "        final_loss = loss1 + loss2\n",
    "        \n",
    "        epoch_loss = epoch_loss + final_loss\n",
    "        \n",
    "        final_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if not eps%10:\n",
    "        print(\"Epoch: %d, Loss: %.3f\" % (eps, epoch_loss.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1,b2,b3,b4 = next(iter(train_dataloader))\n",
    "b1 = b1.cuda()\n",
    "b2 = b2.cuda()\n",
    "b3 = b3.cuda()\n",
    "b4 = b4.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_out,*sentiments= merge_model(b1, b2, b3, b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(list(b1.view(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(list(summary_out.logits.argmax(2).view(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
